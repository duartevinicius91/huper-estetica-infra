# Infraestrutura Huper Est√©tica - Nomad

Este reposit√≥rio cont√©m a configura√ß√£o de infraestrutura para o sistema Huper Est√©tica usando HashiCorp Nomad.

> üí° **Quer come√ßar rapidamente?** Veja o [QUICKSTART.md](QUICKSTART.md) para um guia r√°pido de deploy.

## üìã √çndice

- [Pr√©-requisitos](#pr√©-requisitos)
- [Estrutura do Projeto](#estrutura-do-projeto)
- [Configura√ß√£o Inicial](#configura√ß√£o-inicial)
- [Deploy Manual](#deploy-manual)
- [CI/CD](#cicd)
- [Jobs Nomad](#jobs-nomad)
- [Vari√°veis de Ambiente](#vari√°veis-de-ambiente)
- [Troubleshooting](#troubleshooting)

## Pr√©-requisitos

- **Nomad** instalado e configurado (vers√£o 1.5+)
- **Docker** instalado e em execu√ß√£o
- **Git** para clonar reposit√≥rios
- **Docker Hub** account (ou registry alternativo)
- Acesso ao cluster Nomad

### Instala√ß√£o do Nomad

#### Linux/macOS
```bash
# Baixar e instalar
wget https://releases.hashicorp.com/nomad/1.7.0/nomad_1.7.0_linux_amd64.zip
unzip nomad_1.7.0_linux_amd64.zip
sudo mv nomad /usr/local/bin/
```

#### Windows
```powershell
# Usando Chocolatey
choco install nomad

# Ou baixar manualmente de:
# https://releases.hashicorp.com/nomad/
```

### Configurar Nomad como Servi√ßo Systemd (Ubuntu/Debian)

Para rodar o Nomad como daemon no Ubuntu, use o arquivo `nomad.service` inclu√≠do:

```bash
# 1. Criar diret√≥rio de configura√ß√£o do Nomad
sudo mkdir -p /etc/nomad.d

# 2. Criar arquivo de configura√ß√£o b√°sico
# Voc√™ pode usar o arquivo nomad.hcl.example como refer√™ncia
sudo cp nomad.hcl.example /etc/nomad.d/nomad.hcl
# Ou criar manualmente:
sudo tee /etc/nomad.d/nomad.hcl > /dev/null <<EOF
datacenter = "dc1"
data_dir = "/opt/nomad/data"

server {
  enabled = true
  bootstrap_expect = 1
}

client {
  enabled = true
}
EOF

# 3. Criar diret√≥rios de dados, logs e volumes
sudo mkdir -p /opt/nomad/data
sudo mkdir -p /opt/nomad/volumes/keycloak_data
sudo mkdir -p /opt/nomad/volumes/ollama_data
sudo mkdir -p /var/log/nomad

# Dar permiss√µes adequadas
sudo chown -R root:root /opt/nomad
sudo chmod -R 755 /opt/nomad

# 4. Copiar o arquivo de servi√ßo
sudo cp nomad.service /etc/systemd/system/nomad.service

# 5. Recarregar systemd
sudo systemctl daemon-reload

# 6. Habilitar o servi√ßo para iniciar no boot
sudo systemctl enable nomad

# 7. Iniciar o servi√ßo
sudo systemctl start nomad

# 8. Verificar status
sudo systemctl status nomad

# 9. Ver logs
sudo journalctl -u nomad -f
```

**Comandos √∫teis:**
```bash
# Parar o servi√ßo
sudo systemctl stop nomad

# Reiniciar o servi√ßo
sudo systemctl restart nomad

# Ver logs em tempo real
sudo journalctl -u nomad -f

# Ver √∫ltimas 100 linhas de log
sudo journalctl -u nomad -n 100

# Verificar status
sudo systemctl status nomad
```

## Estrutura do Projeto

```
huper-estetica-infra/
‚îú‚îÄ‚îÄ nomad/                    # Jobs Nomad
‚îÇ   ‚îú‚îÄ‚îÄ postgres.nomad        # Infraestrutura (n√£o utilizado - usa Supabase)
‚îÇ   ‚îú‚îÄ‚îÄ keycloak.nomad        # Infraestrutura
‚îÇ   ‚îú‚îÄ‚îÄ ollama.nomad          # Infraestrutura
‚îÇ   ‚îú‚îÄ‚îÄ huper-estetica.nomad  # Aplica√ß√£o (deploy via pipeline do servi√ßo)
‚îÇ   ‚îî‚îÄ‚îÄ huper-estetica-front.nomad  # Aplica√ß√£o (deploy via pipeline do servi√ßo)
‚îú‚îÄ‚îÄ nomad.service            # Arquivo systemd para rodar Nomad como daemon
‚îú‚îÄ‚îÄ nomad.hcl.example        # Exemplo de configura√ß√£o do Nomad
‚îî‚îÄ‚îÄ .github/workflows/        # CI/CD GitHub Actions
    ‚îî‚îÄ‚îÄ deploy-infrastructure.yml  # Deploy apenas da infraestrutura
```

> **Nota:** Este reposit√≥rio gerencia apenas a infraestrutura (Keycloak, Ollama). O banco de dados PostgreSQL √© gerenciado via Supabase (n√£o √© deployado aqui). Os containers das aplica√ß√µes (`huper-estetica` e `huper-estetica-front`) s√£o atualizados automaticamente pelas pipelines de build de cada reposit√≥rio de servi√ßo.

## Configura√ß√£o Inicial

### 1. Configurar Vari√°veis de Ambiente

Copie o arquivo de exemplo e configure suas vari√°veis:

```bash
cp env.example .env
```

Edite o arquivo `.env` com suas configura√ß√µes:

```bash
# Docker Hub
export DOCKER_HUB_USERNAME=seu_usuario
export DOCKER_HUB_PASSWORD=sua_senha

# Nomad
export NOMAD_ADDR=http://localhost:4646

# Vers√£o das imagens
export VERSION=latest

# PostgreSQL
export POSTGRES_PASSWORD=senha_segura
export POSTGRES_DB=huperestetica
export POSTGRES_USER=postgres

# Keycloak
export KEYCLOAK_ADMIN_USERNAME=admin
export KEYCLOAK_ADMIN_PASSWORD=senha_segura

# Backend
export OPENAI_API_KEY=sua_chave
export STRIPE_SECRET_KEY=sua_chave
export STRIPE_PUBLISHABLE_KEY=sua_chave
export STRIPE_WEBHOOK_SECRET=sua_chave
export FACEBOOK_APP_ID=seu_id
```

### 2. Configurar Supabase

O banco de dados PostgreSQL √© gerenciado via Supabase. Configure as vari√°veis de ambiente com as credenciais do seu projeto Supabase:

- `POSTGRES_HOST`: Host do Supabase (ex: `db.xxxxx.supabase.co`)
- `POSTGRES_PORT`: Porta (geralmente `5432`)
- `POSTGRES_DB`: Nome do banco de dados
- `POSTGRES_USER`: Usu√°rio do banco
- `POSTGRES_PASSWORD`: Senha do banco

### 3. Configurar Volumes Nomad

Os jobs Nomad usam volumes do tipo `host` para persist√™ncia de dados. **Volumes host devem ser configurados no arquivo de configura√ß√£o do cliente Nomad** (`/etc/nomad.d/nomad.hcl`).

**Importante:** Volumes do tipo `host` n√£o podem ser registrados via CLI. Eles devem ser configurados diretamente no arquivo de configura√ß√£o.

Edite o arquivo `/etc/nomad.d/nomad.hcl` e adicione os volumes host na se√ß√£o `client`:

```bash
sudo nano /etc/nomad.d/nomad.hcl
```

Adicione ou atualize a se√ß√£o `client`:

```hcl
client {
  enabled = true
  
  host_volume "keycloak_data" {
    path      = "/opt/nomad/volumes/keycloak_data"
    read_only = false
  }
  
  host_volume "ollama_data" {
    path      = "/opt/nomad/volumes/ollama_data"
    read_only = false
  }
}
```

Crie os diret√≥rios e reinicie o Nomad:

```bash
# Criar diret√≥rios dos volumes
sudo mkdir -p /opt/nomad/volumes/keycloak_data
sudo mkdir -p /opt/nomad/volumes/ollama_data

# Dar permiss√µes adequadas
sudo chown -R root:root /opt/nomad/volumes
sudo chmod -R 755 /opt/nomad/volumes

# Reiniciar Nomad para aplicar mudan√ßas
sudo systemctl restart nomad

# Verificar se os volumes est√£o dispon√≠veis
nomad node status -self
```

## Deploy Manual

### Deploy da Infraestrutura

A infraestrutura (Keycloak, Ollama) pode ser deployada via:

> **Nota:** O banco de dados PostgreSQL √© gerenciado via Supabase e n√£o precisa ser deployado.

**Op√ß√£o 1: Via GitHub Actions (Recomendado)**
```bash
# Execute o workflow "Deploy Infrastructure" manualmente ou fa√ßa push das mudan√ßas nos jobs Nomad
```

**Op√ß√£o 2: Via Nomad CLI**
```bash
export NOMAD_ADDR=http://seu-nomad:4646
nomad job run nomad/keycloak.nomad
nomad job run nomad/ollama.nomad
```

### Deploy das Aplica√ß√µes

As aplica√ß√µes (`huper-estetica` e `huper-estetica-front`) s√£o deployadas automaticamente pelas pipelines de build de cada reposit√≥rio. N√£o √© necess√°rio fazer deploy manual aqui.

### Deploy Individual

```bash
# Deploy de um servi√ßo espec√≠fico de infraestrutura
nomad job run nomad/keycloak.nomad
nomad job run nomad/ollama.nomad

# Deploy das aplica√ß√µes (geralmente feito via pipelines)
nomad job run nomad/huper-estetica.nomad
nomad job run nomad/huper-estetica-front.nomad
```

## CI/CD

### Fluxo de Deploy

1. **Infraestrutura**: Este reposit√≥rio cont√©m um workflow que faz deploy apenas da infraestrutura (Keycloak, Ollama) quando h√° mudan√ßas nos jobs Nomad correspondentes. O banco de dados PostgreSQL √© gerenciado via Supabase.

2. **Aplica√ß√µes**: Cada reposit√≥rio de aplica√ß√£o (`huper-estetica` e `huper-estetica-front`) possui sua pr√≥pria pipeline de build que:
   - Constr√≥i a aplica√ß√£o
   - Cria a imagem Docker
   - Faz push para Docker Hub
   - **Faz deploy autom√°tico no Nomad** usando os jobs deste reposit√≥rio

### Configurar Secrets no GitHub

No reposit√≥rio de infraestrutura (`huper-estetica-infra`), configure:

1. **NOMAD_ADDR**: Endere√ßo do servidor Nomad (ex: `http://nomad.example.com:4646`)
2. **KEYCLOAK_ADMIN_USERNAME**: Usu√°rio admin do Keycloak
3. **KEYCLOAK_ADMIN_PASSWORD**: Senha admin do Keycloak

Nos reposit√≥rios de aplica√ß√£o (`huper-estetica` e `huper-estetica-front`), configure:

1. **DOCKERHUB_USERNAME**: Seu usu√°rio do Docker Hub
2. **DOCKERHUB_ACCESS_TOKEN**: Token de acesso do Docker Hub
3. **NOMAD_ADDR**: Endere√ßo do servidor Nomad
4. **INFRA_REPO_TOKEN**: Token para acessar o reposit√≥rio de infraestrutura (opcional, pode usar GITHUB_TOKEN)
5. **Vari√°veis do Supabase**:
   - **POSTGRES_HOST**: Host do Supabase (ex: `db.xxxxx.supabase.co`)
   - **POSTGRES_PORT**: Porta (geralmente `5432`)
   - **POSTGRES_DB**: Nome do banco de dados
   - **POSTGRES_USER**: Usu√°rio do banco
   - **POSTGRES_PASSWORD**: Senha do banco
6. Todas as outras vari√°veis de ambiente necess√°rias para as aplica√ß√µes (KEYCLOAK_*, etc.)

### Executar Deploy da Infraestrutura Manualmente

1. V√° em **Actions** neste reposit√≥rio
2. Selecione o workflow "Deploy Infrastructure"
3. Clique em **Run workflow**

## Jobs Nomad

### PostgreSQL
> **Nota:** O PostgreSQL n√£o √© deployado via Nomad. O banco de dados √© gerenciado via Supabase. Configure as vari√°veis de ambiente `POSTGRES_HOST`, `POSTGRES_PORT`, `POSTGRES_DB`, `POSTGRES_USER` e `POSTGRES_PASSWORD` com as credenciais do seu projeto Supabase.

### Keycloak
- **Portas**: 7080 (HTTP), 7443 (HTTPS)
- **Volume**: `keycloak_data`
- **Recursos**: 1000 CPU, 1GB RAM

### Ollama
- **Porta**: 11434
- **Volume**: `ollama_data`
- **Recursos**: 2000 CPU, 4GB RAM

### Huper Est√©tica (Backend)
- **Porta**: 8080
- **Recursos**: 1000 CPU, 2GB RAM
- **Depend√™ncias**: PostgreSQL, Keycloak

### Huper Est√©tica Front (Frontend)
- **Porta**: 80
- **Recursos**: 200 CPU, 256MB RAM

## Vari√°veis de Ambiente

### Vari√°veis Globais
- `NOMAD_ADDR`: Endere√ßo do servidor Nomad
- `DOCKER_HUB_USERNAME`: Usu√°rio do Docker Hub
- `VERSION`: Vers√£o/tag das imagens Docker

### Vari√°veis por Servi√ßo

#### PostgreSQL
- `POSTGRES_PASSWORD`: Senha do PostgreSQL
- `POSTGRES_DB`: Nome do banco de dados
- `POSTGRES_USER`: Usu√°rio do PostgreSQL

#### Keycloak
- `KEYCLOAK_ADMIN_USERNAME`: Usu√°rio admin do Keycloak
- `KEYCLOAK_ADMIN_PASSWORD`: Senha admin do Keycloak

#### Backend (huper-estetica)
- `POSTGRES_PASSWORD`: Senha do PostgreSQL
- `POSTGRES_JDBC_URL`: URL de conex√£o JDBC
- `POSTGRES_USER`: Usu√°rio do PostgreSQL
- `KEYCLOAK_AUTH_SERVER_URL`: URL do servidor Keycloak
- `KEYCLOAK_ADMIN`: Usu√°rio admin do Keycloak
- `KEYCLOAK_ADMIN_PASSWORD`: Senha admin do Keycloak
- `OPENAI_API_KEY`: Chave da API OpenAI
- `STRIPE_SECRET_KEY`: Chave secreta do Stripe
- `STRIPE_PUBLISHABLE_KEY`: Chave p√∫blica do Stripe
- `STRIPE_WEBHOOK_SECRET`: Secret do webhook Stripe
- `FACEBOOK_APP_ID`: ID da aplica√ß√£o Facebook

## Comandos √öteis

### Verificar Status dos Jobs
```bash
nomad job status
nomad job status postgres
nomad job status huper-estetica
```

### Ver Logs
```bash
nomad alloc logs <allocation-id>
nomad job logs postgres
nomad job logs huper-estetica
```

### Parar um Job
```bash
nomad job stop postgres
```

### Reiniciar um Job
```bash
nomad job restart postgres
```

### Atualizar um Job
```bash
nomad job run nomad/huper-estetica.nomad
```

### Ver Informa√ß√µes de um Job
```bash
nomad job inspect postgres
```

### Ver Aloca√ß√µes
```bash
nomad alloc status
```

## Troubleshooting

### Erro: "Volume not found" ou "missing compatible host volumes"

**Sintomas:**
```
Constraint "missing compatible host volumes": 1 nodes excluded by filter
```

**Solu√ß√µes:**

1. **Verificar se os volumes est√£o configurados no cliente Nomad:**
   ```bash
   # Verificar configura√ß√£o do cliente
   nomad node status -self
   
   # Ver volumes registrados
   nomad volume status
   ```

2. **Configurar volumes host no arquivo nomad.hcl:**
   ```bash
   # Editar configura√ß√£o
   sudo nano /etc/nomad.d/nomad.hcl
   
   # Adicionar na se√ß√£o client:
   client {
     enabled = true
     
     host_volume "keycloak_data" {
       path      = "/opt/nomad/volumes/keycloak_data"
       read_only = false
     }
     
     host_volume "ollama_data" {
       path      = "/opt/nomad/volumes/ollama_data"
       read_only = false
     }
   }
   
   # Criar diret√≥rios
   sudo mkdir -p /opt/nomad/volumes/keycloak_data
   sudo mkdir -p /opt/nomad/volumes/ollama_data
   
   # Reiniciar Nomad
   sudo systemctl restart nomad
   ```

3. **Verificar se os volumes est√£o configurados corretamente:**
   ```bash
   # Verificar configura√ß√£o do n√≥
   nomad node status -self
   
   # Verificar se o Nomad est√° rodando com a nova configura√ß√£o
   sudo systemctl status nomad
   ```

4. **Verificar se os diret√≥rios existem e t√™m permiss√µes corretas:**
   ```bash
   ls -la /opt/nomad/volumes/
   sudo chown -R root:root /opt/nomad/volumes
   sudo chmod -R 755 /opt/nomad/volumes
   ```

### Erro: "Cannot connect to Nomad" ou "connection refused"

**Sintomas:**
```
Error submitting job: Put "http://127.0.0.1:4646/v1/jobs": dial tcp 127.0.0.1:4646: connect: connection refused
```

**Solu√ß√µes:**

1. **Verificar se o Nomad est√° rodando:**
   ```bash
   # Verificar status do servi√ßo (Linux)
   sudo systemctl status nomad
   
   # Ou verificar processos
   ps aux | grep nomad
   ```

2. **Iniciar o Nomad em modo dev (para desenvolvimento local):**
   ```bash
   nomad agent -dev
   ```
   Isso iniciar√° um servidor Nomad local em `http://127.0.0.1:4646`

3. **Configurar NOMAD_ADDR para servidor remoto:**
   ```bash
   export NOMAD_ADDR=http://seu-servidor-nomad:4646
   # ou adicione ao seu arquivo .env
   echo "NOMAD_ADDR=http://seu-servidor-nomad:4646" >> .env
   ```

4. **Verificar conectividade:**
   ```bash
   # Testar conex√£o
   nomad server members
   # ou
   curl http://127.0.0.1:4646/v1/status/leader
   ```

5. **Se estiver usando um servidor remoto, verifique:**
   - Se o servidor est√° acess√≠vel na rede
   - Se a porta 4646 est√° aberta no firewall
   - Se h√° autentica√ß√£o necess√°ria (configure `NOMAD_TOKEN`)

### Erro: "Image pull failed"
**Solu√ß√£o**: 
1. Verifique se a imagem existe no Docker Hub
2. Verifique as credenciais do Docker Hub
3. Verifique se o Nomad tem acesso ao Docker Hub

### Erro: "Service check failed"
**Solu√ß√£o**: 
1. Verifique os logs do servi√ßo: `nomad job logs <job-name>`
2. Verifique se as depend√™ncias est√£o rodando
3. Verifique as vari√°veis de ambiente

### Backend n√£o consegue conectar ao PostgreSQL
**Solu√ß√£o**: 
1. Verifique se o PostgreSQL est√° rodando: `nomad job status postgres`
2. Verifique a URL de conex√£o JDBC nas vari√°veis de ambiente
3. Verifique se o servi√ßo est√° registrado corretamente no Consul (se estiver usando)

### Frontend n√£o consegue acessar a API
**Solu√ß√£o**:
1. Verifique se o backend est√° rodando
2. Verifique a vari√°vel `VITE_HUPER_ABBY_API_URL` no job do frontend
3. Verifique as configura√ß√µes de CORS no backend

## Pr√≥ximos Passos

- [ ] Configurar Traefik para roteamento reverso
- [ ] Adicionar health checks mais robustos
- [ ] Configurar backups autom√°ticos
- [ ] Adicionar monitoramento (Prometheus/Grafana)
- [ ] Configurar autoscaling
- [ ] Adicionar secrets management (Vault)

## Suporte

Para problemas ou d√∫vidas, abra uma issue no reposit√≥rio ou entre em contato com a equipe de infraestrutura.
